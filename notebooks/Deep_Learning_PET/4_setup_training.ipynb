{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up a training loop with validation.\n",
    "\n",
    "This demo is a jupyter notebook, i.e. intended to be run step by step.\n",
    "\n",
    "Author: Imraj Singh\n",
    "\n",
    "First version: 13th of May 2022\n",
    "\n",
    "CCP SyneRBI Synergistic Image Reconstruction Framework (SIRF).\n",
    "Copyright 2022 University College London.\n",
    "\n",
    "This is software developed for the Collaborative Computational Project in Synergistic Reconstruction for Biomedical Imaging (http://www.ccpsynerbi.ac.uk/).\n",
    "\n",
    "SPDX-License-Identifier: Apache-2.0\n",
    "\n",
    "# Setting up the training\n",
    "\n",
    "This is very standard pytorch parlance..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The components:\n",
    "* Setup acquisition model\n",
    "* Setup dataset\n",
    "* Setup model\n",
    "* Setup training loop with validation\n",
    "\n",
    "First we import the prerequisite packages, set up the forward operator, dataset and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the PET reconstruction engine\n",
    "import sirf.STIR as pet\n",
    "# Set the verbosity\n",
    "pet.set_verbosity(0)\n",
    "# Store temporary sinograms in RAM\n",
    "pet.AcquisitionData.set_storage_scheme(\"memory\")\n",
    "# SIRF STIR message redirector\n",
    "import sirf\n",
    "msg = sirf.STIR.MessageRedirector(info=None, warn=None, errr=None)\n",
    "# Load dataset and model\n",
    "from odl_funcs.ellipses import EllipsesDataset\n",
    "from lpd_net import LearnedPrimalDual\n",
    "# Import standard extra packages\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from tqdm.notebook import trange, tqdm\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "size_xy = 128\n",
    "mini_batch = 1\n",
    "n_samples = 10\n",
    "\n",
    "from sirf.Utilities import examples_data_path\n",
    "sinogram_template = pet.AcquisitionData(examples_data_path('PET')\\\n",
    "                                        + '/thorax_single_slice/template_sinogram.hs');\n",
    "# create acquisition model\n",
    "acq_model = pet.AcquisitionModelUsingParallelproj();\n",
    "image_template = sinogram_template.create_uniform_image(1.0,size_xy);\n",
    "acq_model.set_up(sinogram_template,image_template);\n",
    "train_dataloader = torch.utils.data.DataLoader( \\\n",
    "    EllipsesDataset(acq_model.forward, image_template, mode=\"train\", n_samples = n_samples) \\\n",
    "    , batch_size=mini_batch, shuffle=True)\n",
    "valid_dataloader = torch.utils.data.DataLoader( \\\n",
    "    EllipsesDataset(acq_model.forward, image_template, mode=\"valid\") \\\n",
    "    , batch_size=1, shuffle=True)\n",
    "model = LearnedPrimalDual(image_template, sinogram_template,\\\n",
    "                          acq_model, n_iter = 2, n_primal = 5, n_dual = 5, n_layers = 5, n_feature_channels = 128).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some trained data (trained.torch_model and results.npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trained network hyperparameters:\n",
    "# lr = 5e-4\n",
    "# betas = (0.99, 0.999)\n",
    "# batch = 10\n",
    "# size_xy = 128\n",
    "# n_samples = 50\n",
    "if not (os.path.exists('trained.torch_model') and os.path.exists('results.npy')):\n",
    "    !curl -L -o \"trained.torch_model\" \"https://zenodo.org/record/7316151/files/trained.torch_model\"\n",
    "    !curl -L -o \"results.npy\" \"https://zenodo.org/record/7316151/files/results.npy\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up the training loop with validation and a very simply \"data logger\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-8\n",
    "total_epochs = 1000\n",
    "\n",
    "criterion = torch.nn.MSELoss(reduction='sum').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.99, 0.999))\n",
    "\n",
    "data_log = {}\n",
    "data_log[\"valid_loss\"] = []\n",
    "data_log[\"valid_image\"] = []\n",
    "data_log[\"loss\"] = []\n",
    "\n",
    "min_valid_loss = 1e9\n",
    "\n",
    "x_gt_valid, y_valid = next(iter(valid_dataloader))\n",
    "x_gt_valid, y_valid = x_gt_valid.float().to(device), y_valid.float().to(device)\n",
    "\n",
    "if os.path.exists('trained.torch_model'):\n",
    "    checkpoint = torch.load('trained.torch_model')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "pbar1 = trange(total_epochs, position=0, leave=True, desc='Epochs')\n",
    "pbar2 = tqdm(train_dataloader, position=1, leave=True, desc='Iterations')\n",
    "for i in pbar1:\n",
    "    model.eval()\n",
    "    x_valid = model(y_valid);\n",
    "    loss_valid = criterion(x_gt_valid, x_valid)\n",
    "    pbar1.set_description(\"Epoch, validation loss {:10.2f}\".format(loss_valid.item()))\n",
    "    data_log[\"valid_loss\"].append(loss_valid.item())\n",
    "    data_log[\"valid_image\"].append(x_valid[0,0,...].detach().cpu().numpy())\n",
    "    if min_valid_loss > loss_valid.item():\n",
    "        best_model = model.state_dict()\n",
    "        best_optim = optimizer.state_dict()\n",
    "    pbar2.reset(int(np.ceil(n_samples/mini_batch)))\n",
    "    for ii, (x_gt, y) in enumerate(train_dataloader):\n",
    "        x_gt, y = x_gt.float().to(device), y.float().to(device)\n",
    "        model.train();\n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "        x = model(y);\n",
    "        # Compute and print loss\n",
    "        loss = criterion(x_gt, x)\n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        optimizer.step()\n",
    "        data_log[\"loss\"].append(loss.item())\n",
    "        pbar2.update()\n",
    "        pbar2.set_description(\"Batch sample, training loss {:10.2f}\".format(loss.item()))\n",
    "\n",
    "torch.save({'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, 'trained_extra.torch_model')\n",
    "np.save('results',data_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look as some of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('results.npy'):\n",
    "    r = np.load('results.npy',allow_pickle=True).item()\n",
    "    min_loss = np.argmin(r['valid_loss'])\n",
    "    print('Minimum validation loss is: {} at epoch {}'.format(r['valid_loss'][min_loss],min_loss))\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1,3,figsize=(15,5))\n",
    "    ax1.plot(np.log(r['loss']))\n",
    "    ax1.set_title('log(Training MSE)')\n",
    "    ax2.plot(np.log(r['valid_loss']))\n",
    "    ax2.set_title('log(Validation MSE)')\n",
    "    ax3.imshow(np.flipud(r['valid_image'][min_loss].T))\n",
    "    ax3.set_title('Best validation image with MSE: ' + str(r['valid_loss'][min_loss]))\n",
    "    ax3.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "* Do inference of BrainWeb data (i.e. add a test set)\n",
    "* See the reconstruction at various points in the network\n",
    "* Compare with OSEM reconstruction\n",
    "* Attempt to improve the model (change training parameters?)\n",
    "* Use \"realistic\" acquisition model for training data generation, but \"simple\" acquisition model for reconstruction\n",
    "* Use more \"realistic\" acquisition model for reconstruction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  },
  "vscode": {
   "interpreter": {
    "hash": "cee20aa2885cadc07e824ce5082d40bca942426616eda434cad5578791d33ff8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
